{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "|2024-10-31|13:44:10.671| [WARNING] /home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "\n",
      "|2024-10-31|13:44:10.672| [WARNING] /home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "\n",
      "|2024-10-31|13:44:10.673| [WARNING] /home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "\n",
      "|2024-10-31|13:44:12.637| [WARNING] /home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    get_efficientunet_b0_MBConv,\n",
    ")\n",
    "import skimage\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "from monkey.config import TrainingIOConfig\n",
    "from monkey.data.dataset import get_dataloaders\n",
    "from monkey.data.data_utils import (\n",
    "    imagenet_denormalise,\n",
    "    load_json_annotation,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "import skimage\n",
    "from evaluation.evaluate import match_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_centers(cell_mask):\n",
    "    mask_label = skimage.measure.label(cell_mask)\n",
    "    stats = skimage.measure.regionprops(mask_label)\n",
    "    centers = []\n",
    "    for region in stats:\n",
    "        centroid = region[\"centroid\"]\n",
    "        centers.append(centroid)\n",
    "    return centers\n",
    "\n",
    "\n",
    "SPACING_LEVEL0 = 0.24199951445730394\n",
    "\n",
    "\n",
    "def evaluate_cell_predictions(gt_centers, pred_centers):\n",
    "    tp_x_coords = []\n",
    "    tp_y_coords = []\n",
    "\n",
    "    # print(f\"Total gt cells: {len(gt_centers)}\")\n",
    "    # print(f\"Total pred cells: {len(pred_centers)}\")\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    result_prob = [1.0 for i in range(len(pred_centers))]\n",
    "    (\n",
    "        tp,\n",
    "        fn,\n",
    "        fp,\n",
    "        tp_probs,\n",
    "        fp_probs,\n",
    "    ) = match_coordinates(\n",
    "        gt_centers,\n",
    "        pred_centers,\n",
    "        result_prob,\n",
    "        int(7.5 / SPACING_LEVEL0),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 1\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 1\n",
    "    try:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 1\n",
    "\n",
    "    # print(f\"True Positives: {tp}\")\n",
    "    # print(f\"False Positives: {fp}\")\n",
    "    # print(f\"False Negatives: {fn}\")\n",
    "    # print(f\"f1 = {f1}\")\n",
    "    # print(f\"precision = {precision}\")\n",
    "    # print(f\"recall = {recall}\")\n",
    "\n",
    "    return tp_x_coords, tp_y_coords, f1, precision, recall\n",
    "\n",
    "\n",
    "def erode_mask(mask):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5425, 10368]\n",
      "train patches: 15793\n",
      "test patches: 4362\n"
     ]
    }
   ],
   "source": [
    "# model = get_efficientunet_b0_MBConv(pretrained=False)\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"mit_b5\",\n",
    "    encoder_weights=None,\n",
    "    decoder_attention_type=\"scse\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ")\n",
    "\n",
    "val_fold = 3\n",
    "\n",
    "checkpoint_path = f\"/home/u1910100/Documents/Monkey/runs/MiTB5Unet/fold_{val_fold}/epoch_75.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.to(\"cuda\")\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    "    save_dir=f\"./\",\n",
    ")\n",
    "\n",
    "# Get dataloaders for task\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=val_fold,\n",
    "    task=1,\n",
    "    batch_size=1,\n",
    "    disk_radius=11,\n",
    "    do_augmentation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4362 [00:00<?, ?it/s]|2024-10-31|13:52:14.695| [WARNING] /tmp/ipykernel_367697/3771032546.py:44: UserWarning: Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?\n",
      "  out_mask = skimage.morphology.remove_small_objects(\n",
      "\n",
      "100%|██████████| 4362/4362 [01:43<00:00, 41.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1  0.7980072834525814\n",
      "Avg Precision  0.7950164731238576\n",
      "Avg Recall  0.8170303902353496\n",
      "threshold 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4362/4362 [01:43<00:00, 42.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1  0.7998625105586832\n",
      "Avg Precision  0.8040467246045137\n",
      "Avg Recall  0.8111176252940094\n",
      "threshold 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4362/4362 [01:43<00:00, 42.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1  0.8027994492485725\n",
      "Avg Precision  0.814152642183286\n",
      "Avg Recall  0.8055671614262554\n",
      "threshold 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4362/4362 [01:44<00:00, 41.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1  0.8076487814893856\n",
      "Avg Precision  0.8411933154144587\n",
      "Avg Recall  0.7894643897558292\n",
      "best threshold: 0.9\n",
      "best F1: 0.8076487814893856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "# thresholds = [0.9]\n",
    "best_thresh = thresholds[0]\n",
    "best_F1 = 0\n",
    "\n",
    "for thresh in thresholds:\n",
    "    print(f\"threshold {thresh}\")\n",
    "    counter = 0\n",
    "    sum_F1 = []\n",
    "    sum_precison = []\n",
    "    sum_recall = []\n",
    "    for data in tqdm(val_loader):\n",
    "        file_ids = data[\"id\"]\n",
    "\n",
    "        annotation_dict = load_json_annotation(file_ids[0], IOconfig)\n",
    "        images = data[\"image\"].cuda().float()\n",
    "        gt_masks = data[\"mask\"].cuda().float()\n",
    "\n",
    "        image_np = images[0]\n",
    "        image_np = image_np.cpu().numpy()\n",
    "        gt_mask_np = gt_masks[0]\n",
    "        gt_mask_np = gt_mask_np.cpu().numpy()\n",
    "\n",
    "        image_np = np.moveaxis(image_np, 0, 2)\n",
    "        image_np = imagenet_denormalise(image_np)\n",
    "\n",
    "        # fig, axs = plt.subplots(1, 4, figsize=(10,10))\n",
    "        # axs[0].imshow(image_np)\n",
    "        # axs[0].title.set_text(\"Image\")\n",
    "        # axs[1].imshow(gt_mask_np[0], cmap='gray')\n",
    "        # axs[1].title.set_text(\"Ground Truth\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(images)\n",
    "            out = torch.sigmoid(out)\n",
    "\n",
    "        out = out.cpu().detach().numpy()[0][0]\n",
    "\n",
    "        # axs[3].imshow(out, cmap='jet')\n",
    "\n",
    "        out_mask = np.where(out >= thresh, 1, 0).astype(np.uint8)\n",
    "        # out_mask = erode_mask(out_mask)\n",
    "\n",
    "        out_mask = skimage.morphology.remove_small_objects(\n",
    "            ar=out_mask, min_size=32\n",
    "        )\n",
    "\n",
    "        pred_centers = get_cell_centers(out_mask)\n",
    "        true_centers = get_cell_centers(gt_mask_np[0])\n",
    "        xs, ys, f1, precision, recall = evaluate_cell_predictions(\n",
    "            true_centers, pred_centers\n",
    "        )\n",
    "\n",
    "        # axs[2].imshow(out_mask, cmap=\"gray\")\n",
    "        # axs[2].title.set_text(\"Prediction\")\n",
    "\n",
    "        # axs[0].scatter(ys, xs, alpha=0.7)\n",
    "        # axs[1].scatter(ys, xs, alpha=0.5)\n",
    "        # axs[2].scatter(ys, xs, alpha=0.5)\n",
    "\n",
    "        # for ax in fig.axes:\n",
    "        #     ax.axis(\"off\")\n",
    "        # plt.show()\n",
    "\n",
    "        sum_F1.append(f1)\n",
    "        sum_precison.append(precision)\n",
    "        sum_recall.append(recall)\n",
    "\n",
    "        # counter +=1\n",
    "        # if counter > 20:\n",
    "        #     break\n",
    "\n",
    "    print(\"Avg F1 \", np.mean(sum_F1))\n",
    "    print(\"Avg Precision \", np.mean(sum_precison))\n",
    "    print(\"Avg Recall \", np.mean(sum_recall))\n",
    "\n",
    "    if np.mean(sum_F1) > best_F1:\n",
    "        best_F1 = np.mean(sum_F1)\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(f\"best threshold: {best_thresh}\")\n",
    "print(f\"best F1: {best_F1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
