{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    get_efficientunet_b0_MBConv,\n",
    ")\n",
    "import skimage\n",
    "import cv2\n",
    "import torch\n",
    "from monkey.config import TrainingIOConfig\n",
    "from monkey.data.dataset import get_dataloaders\n",
    "from monkey.data.data_utils import (\n",
    "    imagenet_denormalise,\n",
    "    load_json_annotation,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "from monkey.model.utils import get_patch_F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_mask(mask, size=3):\n",
    "    kernel = cv2.getStructuringElement(\n",
    "        cv2.MORPH_ELLIPSE, (size, size)\n",
    "    )\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4889, 10051]\n",
      "train patches: 14940\n",
      "test patches: 5215\n"
     ]
    }
   ],
   "source": [
    "model = get_efficientunet_b0_MBConv(pretrained=False)\n",
    "# model = smp.Unet(\n",
    "#     encoder_name=\"mit_b5\",\n",
    "#     encoder_weights=None,\n",
    "#     decoder_attention_type=\"scse\",\n",
    "#     in_channels=3,\n",
    "#     classes=1,\n",
    "# )\n",
    "\n",
    "val_fold = 1\n",
    "\n",
    "checkpoint_path = f\"/home/u1910100/Documents/Monkey/runs/efficientunetb0_seg_bm/fold_{val_fold}/epoch_100.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.to(\"cuda\")\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    "    save_dir=f\"./\",\n",
    ")\n",
    "\n",
    "# Get dataloaders for task\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=val_fold,\n",
    "    task=1,\n",
    "    batch_size=1,\n",
    "    disk_radius=11,\n",
    "    do_augmentation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5215/5215 [01:09<00:00, 74.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1  0.3775810569595036\n",
      "Median F1  0.41025641025641024\n",
      "Avg Precision  0.38920241331780153\n",
      "Avg Recall  0.4662334340122245\n",
      "best threshold: 0.3\n",
      "best F1: 0.3775810569595036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# thresholds = [0.1]\n",
    "thresholds = [0.3]\n",
    "best_thresh = thresholds[0]\n",
    "best_F1 = 0\n",
    "\n",
    "visualization = False\n",
    "\n",
    "for thresh in thresholds:\n",
    "    print(f\"threshold {thresh}\")\n",
    "    counter = 0\n",
    "    sum_F1 = []\n",
    "    sum_precison = []\n",
    "    sum_recall = []\n",
    "    for data in tqdm(val_loader):\n",
    "        file_ids = data[\"id\"]\n",
    "        # print(file_ids)\n",
    "        annotation_dict = load_json_annotation(file_ids[0], IOconfig)\n",
    "        lymphocyte_coords = annotation_dict[\"lymphocytes\"]\n",
    "        monocyte_coords = annotation_dict[\"monocytes\"]\n",
    "\n",
    "        images = data[\"image\"].cuda().float()\n",
    "        gt_masks = data[\"mask\"]\n",
    "\n",
    "        image_np = images[0]\n",
    "        image_np = image_np.cpu().numpy()\n",
    "        gt_mask_np = gt_masks[0]\n",
    "        gt_mask_np = gt_mask_np.cpu().numpy()\n",
    "\n",
    "        image_np = np.moveaxis(image_np, 0, 2)\n",
    "        image_np = imagenet_denormalise(image_np)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(images)\n",
    "            out = torch.sigmoid(out)\n",
    "            # out = torch.relu(out)\n",
    "\n",
    "        out = out.cpu().detach().numpy()[0][0]\n",
    "        out_mask = np.where(out >= thresh, 1, 0)\n",
    "        out_mask = out_mask.astype(np.uint8)\n",
    "        # out_mask = erode_mask(out_mask, 3)\n",
    "        out_mask = out_mask.astype(bool)\n",
    "        out_mask = skimage.morphology.remove_small_objects(\n",
    "            ar=out_mask, min_size=15\n",
    "        )\n",
    "        out_mask = out_mask.astype(np.uint8)\n",
    "\n",
    "        metrics = get_patch_F1_score(out_mask, gt_mask_np[0], out)\n",
    "        f1, precision, recall = (\n",
    "            metrics[\"F1\"],\n",
    "            metrics[\"Precision\"],\n",
    "            metrics[\"Recall\"],\n",
    "        )\n",
    "\n",
    "        if visualization:\n",
    "            fig, axs = plt.subplots(1, 4, figsize=(10, 10))\n",
    "            axs[0].imshow(image_np)\n",
    "            axs[0].title.set_text(\"Image\")\n",
    "            axs[1].imshow(gt_mask_np[0], cmap=\"gray\")\n",
    "            axs[1].title.set_text(\"Ground Truth\")\n",
    "            axs[2].imshow(out_mask, cmap=\"gray\", alpha=0.6)\n",
    "            axs[2].imshow(image_np, alpha=0.4)\n",
    "            axs[2].title.set_text(\"Prediction\")\n",
    "            axs[3].imshow(out, cmap=\"jet\")\n",
    "            for ax in fig.axes:\n",
    "                ax.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        sum_F1.append(f1)\n",
    "        sum_precison.append(precision)\n",
    "        sum_recall.append(recall)\n",
    "\n",
    "        # counter +=1\n",
    "        # if counter > 20:\n",
    "        #     break\n",
    "\n",
    "    sum_F1 = [x for x in sum_F1 if x is not None]\n",
    "    sum_precison = [x for x in sum_precison if x is not None]\n",
    "    sum_recall = [x for x in sum_recall if x is not None]\n",
    "\n",
    "    print(\"Avg F1 \", np.mean(sum_F1))\n",
    "    print(\"Median F1 \", np.median(sum_F1))\n",
    "    print(\"Avg Precision \", np.mean(sum_precison))\n",
    "    print(\"Avg Recall \", np.mean(sum_recall))\n",
    "\n",
    "    if np.mean(sum_F1) > best_F1:\n",
    "        best_F1 = np.mean(sum_F1)\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(f\"best threshold: {best_thresh}\")\n",
    "print(f\"best F1: {best_F1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
