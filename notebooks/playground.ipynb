{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A place to test random stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monkey.model.utils import (\n",
    "    get_classification_metrics,\n",
    "    get_activation_function,\n",
    ")\n",
    "from monkey.model.loss_functions import get_loss_function, dice_coeff\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mask = torch.zeros(size=(1, 1, 256, 256))\n",
    "true_mask[0, 0, 0, 0] = 0.5\n",
    "print(true_mask)\n",
    "pred_mask = torch.zeros(size=(1, 1, 256, 256))\n",
    "print(pred_mask)\n",
    "true_mask[0, 0, 0, 0] = 0.5\n",
    "loss_fn = get_loss_function(\"Jaccard_Loss\")\n",
    "loss = loss_fn.compute_loss(pred_mask, true_mask)\n",
    "pprint(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.zeros(size=(16, 3, 256, 256))\n",
    "# test[0,0,0,0] = 1\n",
    "\n",
    "no_pos = torch.count_nonzero(test).item()\n",
    "no_negs = torch.numel(test) - no_pos\n",
    "print(no_negs, no_pos)\n",
    "# weight = no_negs / no_pos\n",
    "# print(weight)\n",
    "eps = 1e-6\n",
    "weight_0 = torch.numel(test) / (2 * no_negs + eps)\n",
    "weight_1 = torch.numel(test) / (2 * no_pos + eps)\n",
    "\n",
    "print(weight_0)\n",
    "print(weight_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conch.open_clip_custom import (\n",
    "    create_model_from_pretrained,\n",
    "    tokenize,\n",
    "    get_tokenizer,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = \"conch_ViT-B-16\"\n",
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "checkpoint_path = \"/home/u1910100/Downloads/pytorch_model.bin\"\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    model_cfg, checkpoint_path, device=device\n",
    ")\n",
    "_ = model.eval()\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "classes = [\"lymphocyte\", \"monocyte\"]\n",
    "prompts = [\n",
    "    \"a PAS stained image of a lymphocyte\",\n",
    "    \"a PAS stained image of a monocyte\",\n",
    "]\n",
    "\n",
    "tokenized_prompts = tokenize(texts=prompts, tokenizer=tokenizer).to(\n",
    "    device\n",
    ")\n",
    "tokenized_prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monkey.data.dataset import get_classification_dataloaders\n",
    "from monkey.config import TrainingIOConfig\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/classification\",\n",
    "    save_dir=\"./\",\n",
    ")\n",
    "IOconfig.set_image_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "IOconfig.set_mask_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "batch_size = 32\n",
    "train_loader, val_loader = get_classification_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=1,\n",
    "    batch_size=batch_size,\n",
    "    do_augmentation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_list = []\n",
    "true_labels_list = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    file_ids = data[\"id\"]\n",
    "\n",
    "    images, true_labels = (\n",
    "        data[\"image\"].cuda().float(),\n",
    "        data[\"label\"].cpu().tolist(),\n",
    "    )\n",
    "\n",
    "    true_labels_list.extend(true_labels)\n",
    "    pred_probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        image_embedings = model.encode_image(images)\n",
    "        text_embedings = model.encode_text(tokenized_prompts)\n",
    "        sim_scores = (\n",
    "            (\n",
    "                image_embedings\n",
    "                @ text_embedings.T\n",
    "                * model.logit_scale.exp()\n",
    "            )\n",
    "            .softmax(dim=-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "        pred_probs_list.extend(sim_scores[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monkey.model.utils import get_classification_metrics\n",
    "\n",
    "pred_probs_list = np.array(pred_probs_list)\n",
    "true_labels_list = np.array(true_labels_list)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(\n",
    "    true_labels_list, pred_probs_list\n",
    ")\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(\n",
    "    fpr=fpr,\n",
    "    tpr=tpr,\n",
    "    roc_auc=roc_auc,\n",
    "    estimator_name=\"cell classifier\",\n",
    ")\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "thresh = 0.5\n",
    "pred_labels_list = np.where(pred_probs_list > thresh, 1, 0)\n",
    "scores = get_classification_metrics(\n",
    "    true_labels_list, pred_labels_list\n",
    ")\n",
    "print(scores)\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    true_labels_list,\n",
    "    pred_labels_list,\n",
    "    display_labels=[\"lymphocyte\", \"monocyte\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_loader))\n",
    "images = data[\"image\"].to(\"cuda\").float()\n",
    "print(data[\"label\"])\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image_embedings = model.encode_image(images)\n",
    "    text_embedings = model.encode_text(tokenized_prompts)\n",
    "    sim_scores = (\n",
    "        (image_embedings @ text_embedings.T * model.logit_scale.exp())\n",
    "        .softmax(dim=-1)\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "pred_class = sim_scores.argmax()\n",
    "print(pred_class)\n",
    "print(sim_scores)\n",
    "print(sim_scores[:, 1])\n",
    "# print(\"Predicted class:\", classes[sim_scores.argmax()])\n",
    "# print(\n",
    "#     \"Normalized similarity scores:\",\n",
    "#     [\n",
    "#         f\"{cls}: {score:.3f}\"\n",
    "#         for cls, score in zip(classes, sim_scores[0])\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CellViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "from monkey.model.cellvit.cellvit import CellViT256, CellVit256_Unet\n",
    "\n",
    "model_path = \"/home/u1910100/Downloads/HIPT_vit256_small_dino.pth\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model = CellVit256_Unet(num_decoders=3)\n",
    "\n",
    "model.load_pretrained_encoder(model_path)\n",
    "\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "test = torch.rand(size=(4, 3, 256, 256))\n",
    "out = model(test)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapDe Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from scipy import ndimage, signal\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from monkey.data.data_utils import erode_mask, generate_regression_map\n",
    "import cv2\n",
    "from skimage import draw\n",
    "\n",
    "cell_mask = np.zeros(shape=(256, 256), dtype=np.uint8)\n",
    "rr, cc = draw.ellipse(100, 100, 1, 1, shape=cell_mask.shape)\n",
    "# rr, cc = 100, 100\n",
    "cell_mask[rr, cc] = 1\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def gauss_2d_filter(shape=(11, 11)):\n",
    "    sigma = int((shape[0] - 1) / 6)\n",
    "    m, n = [(ss - 1.0) / 2.0 for ss in shape]\n",
    "    y, x = np.ogrid[-m : m + 1, -n : n + 1]\n",
    "    h = np.exp(-(x * x + y * y) / (2.0 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "\n",
    "    h = h / (h[int(m), int(n)])\n",
    "    return h\n",
    "\n",
    "\n",
    "dist_filter = gauss_2d_filter(shape=(17, 17))\n",
    "plt.imshow(dist_filter)\n",
    "plt.show()\n",
    "# cell_mask = generate_regression_map(cell_mask, d_thresh=5, alpha=0.5, scale=1)\n",
    "# plt.imshow(cell_mask)\n",
    "# plt.show()\n",
    "\n",
    "cell_mask = signal.convolve2d(cell_mask, dist_filter)\n",
    "print(np.max(cell_mask))\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multihead Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "from torchvision.models.efficientnet import (\n",
    "    efficientnet_b0,\n",
    ")\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    get_multihead_efficientunet,\n",
    ")\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "model = get_multihead_efficientunet(\n",
    "    out_channels=[2, 1], pretrained=True\n",
    ")\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "summary(model, input_size=(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_input = torch.ones(\n",
    "        size=(1, 3, 256, 256), dtype=torch.float, device=\"cuda\"\n",
    "    )\n",
    "    model_out = model(test_input)\n",
    "    pprint(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapDe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from monkey.model.mapde.model import MapDe\n",
    "from monkey.data.dataset import get_detection_dataloaders\n",
    "from monkey.config import TrainingIOConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monkey.data.data_utils import imagenet_denormalise\n",
    "import torch\n",
    "\n",
    "use_nuclick_masks = False\n",
    "batch_size = 1\n",
    "module = \"detection\"\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    "    save_dir=\"./\",\n",
    ")\n",
    "\n",
    "\n",
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=5,\n",
    "    dataset_name=\"detection\",\n",
    "    batch_size=batch_size,\n",
    "    disk_radius=1,\n",
    "    regression_map=False,\n",
    "    do_augmentation=True,\n",
    "    module=module,\n",
    "    use_nuclick_masks=use_nuclick_masks,\n",
    "    include_background_channel=False,\n",
    ")\n",
    "\n",
    "\n",
    "model = MapDe(3, 30, 50, num_classes=1, filter_size=31)\n",
    "model.eval()\n",
    "# print(model)\n",
    "test_input = torch.ones(size=(4, 3, 252, 252), dtype=torch.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "print(f\"output size = {out.size()}\")\n",
    "# print(torch.max(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 18))\n",
    "\n",
    "image = data[\"image\"][0].numpy()\n",
    "image = np.moveaxis(image, 0, 2)\n",
    "image = imagenet_denormalise(image)\n",
    "axes[0].imshow(image)\n",
    "\n",
    "mask = data[\"mask\"]\n",
    "mask_filtered = model.blur_cell_points(mask)\n",
    "\n",
    "\n",
    "axes[1].imshow(image, alpha=0.5)\n",
    "mask_filtered_numpy = mask_filtered.numpy()\n",
    "axes[1].imshow(mask_filtered_numpy[0][0], alpha=0.5)\n",
    "axes[2].imshow(mask_filtered_numpy[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logits = torch.rand(size=(2, 3, 252, 252))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(test_logits)\n",
    "    probs = model.logits_to_probs(logits)\n",
    "print(logits)\n",
    "\n",
    "out_masks = model.postproc(logits)\n",
    "out_masks = out_masks[:, np.newaxis, :, :]\n",
    "out_masks = model.blur_cell_points(out_masks)\n",
    "\n",
    "logits = logits.numpy(force=True)\n",
    "probs = probs.numpy(force=True)\n",
    "\n",
    "\n",
    "plt.imshow(logits[0][0])\n",
    "plt.show()\n",
    "print(np.max(logits[0][0]))\n",
    "\n",
    "plt.imshow(probs[0][0])\n",
    "plt.show()\n",
    "\n",
    "# print(np.max(logits))\n",
    "plt.imshow(out_masks[0][0])\n",
    "plt.show()\n",
    "\n",
    "import skimage\n",
    "\n",
    "inflamm_labels = skimage.measure.label(out_masks[0][0])\n",
    "inflamm_stats = skimage.measure.regionprops(\n",
    "    inflamm_labels, intensity_image=probs[0][0]\n",
    ")\n",
    "for region in inflamm_stats:\n",
    "    centroid = region[\"centroid\"]\n",
    "\n",
    "    c, r, confidence = (\n",
    "        centroid[1],\n",
    "        centroid[0],\n",
    "        region[\"mean_intensity\"],\n",
    "    )\n",
    "    print(c, r, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoverNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from monkey.model.hovernext.model import (\n",
    "    get_custom_hovernext,\n",
    "    get_convnext_unet,\n",
    "    get_timm_encoder,\n",
    "    load_encoder_weights,\n",
    ")\n",
    "\n",
    "model = get_custom_hovernext(\n",
    "    enc=\"tf_efficientnetv2_s.in21k\",\n",
    "    pretrained=False,\n",
    "    num_heads=3,\n",
    "    decoders_out_channels=[1, 1, 1],\n",
    ")\n",
    "# model = get_convnext_unet(\n",
    "#     out_classes=2, use_batchnorm=True, attention_type=\"scse\"\n",
    "# )\n",
    "# checkpoint_path = \"/home/u1910100/Downloads/lizard_convnextv2_large/train/best_model\"\n",
    "# model = load_encoder_weights(model, checkpoint_path)\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "pprint(summary(model, input_size=(8, 3, 256, 256)))\n",
    "pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "test_input = torch.ones(\n",
    "    size=(1, 3, 256, 256), dtype=torch.float, device=\"cuda\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pannuke Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from monkey.data.data_utils import (\n",
    "    generate_regression_map,\n",
    "    dilate_mask,\n",
    "    load_image,\n",
    "    load_mask,\n",
    ")\n",
    "from monkey.data.dataset import class_mask_to_multichannel_mask\n",
    "\n",
    "cell_mask = np.zeros(shape=(256, 256), dtype=np.uint8)\n",
    "cell_mask[100, 100] = 1\n",
    "\n",
    "cell_mask = dilate_mask(cell_mask, 3)\n",
    "\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()\n",
    "\n",
    "cell_mask = generate_regression_map(\n",
    "    cell_mask, d_thresh=7, alpha=3, scale=1\n",
    ")\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = \"/home/u1910100/Documents/Monkey/patches_256/annotations/masks/C_P000029_18592_66528_18848_66784.npy\"\n",
    "mask = np.load(mask_path)\n",
    "class_mask = class_mask_to_multichannel_mask(mask)\n",
    "\n",
    "plt.imshow(class_mask[0])\n",
    "plt.show()\n",
    "plt.imshow(class_mask[1])\n",
    "plt.show()\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "dist = ndi.distance_transform_edt(class_mask[0] == 0)\n",
    "M = (np.exp(3 * (1 - dist / 7)) - 1) / (np.exp(3) - 1)\n",
    "M[M < 0] = 0\n",
    "M *= 1\n",
    "\n",
    "plt.imshow(M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from strong_augment import StrongAugment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trnsf = T.Compose(\n",
    "    [\n",
    "        StrongAugment(\n",
    "            operations=[2, 3, 4], probabilites=[0.5, 0.3, 0.2]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the images\n",
    "image = np.load(\n",
    "    \"/home/u1910100/Documents/Monkey/patches_256/images/A_P000001_9632_87360_9888_87616.npy\"\n",
    ")\n",
    "aug_image = trnsf(image)\n",
    "\n",
    "# Create a subplot with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Display the original image\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# image = image / 255.0\n",
    "# Display the augmented image\n",
    "axes[1].imshow(\n",
    "    aug_image\n",
    ")  # Permute the dimensions for correct display\n",
    "axes[1].set_title(\"Augmented Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from monkey.model.hovernext.modified_self_attention import (\n",
    "    get_model,\n",
    "    ModifiedSelfAttention,\n",
    ")\n",
    "\n",
    "model = get_model(\n",
    "    enc=\"tf_efficientnetv2_s\",\n",
    "    pretrained=False,\n",
    ")\n",
    "pprint(summary(model, input_size=(1, 3, 256, 256)))\n",
    "\n",
    "test_input = torch.ones(\n",
    "    size=(1, 3, 256, 256), dtype=torch.float, device=\"cuda\"\n",
    ")\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from monkey.model.hovernext.modified_self_attention import (\n",
    "    get_model,\n",
    "    ModifiedSelfAttention,\n",
    ")\n",
    "0\n",
    "attention_module = ModifiedSelfAttention()\n",
    "print(summary(attention_module, input_size=(1, 192, 256, 256)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process NuClick Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "NUCLICK_DIR = \"/home/u1910100/Documents/Monkey/patches_256/annotations/nuclick_hovernext\"\n",
    "\n",
    "SAVE_DIR = \"/home/u1910100/Documents/Monkey/patches_256/annotations/nuclick_masks_processed_v2\"\n",
    "\n",
    "\n",
    "def process_instance_and_class_map(instance_map, class_map):\n",
    "    # get initial binary mask from instance map\n",
    "    binary_mask = np.zeros(shape=(instance_map.shape), dtype=np.uint8)\n",
    "    binary_mask = np.where(instance_map > 0, 1, 0).astype(np.uint8)\n",
    "\n",
    "    lymph_mask = np.where(class_map == 1, 1, 0).astype(np.uint8)\n",
    "    mono_mask = np.where(class_map == 2, 1, 0).astype(np.uint8)\n",
    "\n",
    "    # Erode binary mask by gradient map\n",
    "    sx = ndimage.sobel(instance_map, axis=0)\n",
    "    sy = ndimage.sobel(instance_map, axis=1)\n",
    "    inflamm_gradient = np.hypot(sx, sy)\n",
    "    inflamm_gradient = (inflamm_gradient > 0).astype(np.uint8)\n",
    "    binary_mask[inflamm_gradient == 1] = 0\n",
    "\n",
    "    # Use instance mask to separate lymph and mono instances\n",
    "    lymph_mask[binary_mask == 0] = 0\n",
    "    mono_mask[binary_mask == 0] = 0\n",
    "\n",
    "    # Erode lymph_mask by gradient map\n",
    "    sx = ndimage.sobel(lymph_mask, axis=0)\n",
    "    sy = ndimage.sobel(lymph_mask, axis=1)\n",
    "    lymph_gradient = np.hypot(sx, sy)\n",
    "    lymph_gradient = (lymph_gradient > 0).astype(np.uint8)\n",
    "    lymph_mask[lymph_gradient == 1] = 0\n",
    "\n",
    "    # Erode mono_mask by gradient map\n",
    "    sx = ndimage.sobel(mono_mask, axis=0)\n",
    "    sy = ndimage.sobel(mono_mask, axis=1)\n",
    "    mono_gradient = np.hypot(sx, sy)\n",
    "    mono_gradient = (mono_gradient > 0).astype(np.uint8)\n",
    "    mono_mask[mono_gradient == 1] = 0\n",
    "\n",
    "    return {\n",
    "        \"inflamm_mask\": binary_mask,\n",
    "        \"inflamm_contour_mask\": inflamm_gradient,\n",
    "        \"lymph_mask\": lymph_mask,\n",
    "        \"lymph_contour_mask\": lymph_gradient,\n",
    "        \"mono_mask\": mono_mask,\n",
    "        \"mono_contour_mask\": mono_gradient,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_nuclick_data_file(file_name):\n",
    "    data_path = os.path.join(NUCLICK_DIR, file_name)\n",
    "    data = np.load(data_path)\n",
    "\n",
    "    print(data.shape)\n",
    "\n",
    "    image = data[:, :, 0:3]\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    instance_map = data[:, :, 3]\n",
    "    class_map = data[:, :, 4]\n",
    "\n",
    "\n",
    "    processed_masks = process_instance_and_class_map(\n",
    "        instance_map, class_map\n",
    "    )\n",
    "\n",
    "    new_data = np.zeros(\n",
    "        shape=(data.shape[0], data.shape[1], 9), dtype=np.uint8\n",
    "    )\n",
    "    new_data[:, :, 0:3] = image\n",
    "    new_data[:, :, 3] = processed_masks[\"inflamm_mask\"]\n",
    "    new_data[:, :, 4] = processed_masks[\"inflamm_contour_mask\"]\n",
    "    new_data[:, :, 5] = processed_masks[\"lymph_mask\"]\n",
    "    new_data[:, :, 6] = processed_masks[\"lymph_contour_mask\"]\n",
    "    new_data[:, :, 7] = processed_masks[\"mono_mask\"]\n",
    "    new_data[:, :, 8] = processed_masks[\"mono_contour_mask\"]\n",
    "\n",
    "    # save_path = os.path.join(SAVE_DIR, file_name)\n",
    "    # np.save(save_path, new_data)\n",
    "    return new_data\n",
    "\n",
    "files = os.listdir(NUCLICK_DIR)\n",
    "\n",
    "for file in files:\n",
    "  \n",
    "    new_data = process_nuclick_data_file(file)\n",
    "\n",
    "    # Plot new data\n",
    "    fig, axes = plt.subplots(1, 7, figsize=(18, 18))\n",
    "    axes[0].imshow(new_data[:, :, 0:3])\n",
    "    axes[0].title.set_text(\"Image\")\n",
    "    axes[1].imshow(new_data[:, :, 3])\n",
    "    axes[1].title.set_text(\"Inflammation Mask\")\n",
    "    axes[2].imshow(new_data[:, :, 4])\n",
    "    axes[2].title.set_text(\"Inflammation Contour Mask\")\n",
    "    axes[3].imshow(new_data[:, :, 5])\n",
    "    axes[3].title.set_text(\"Lymph Mask\")\n",
    "    axes[4].imshow(new_data[:, :, 6])\n",
    "    axes[4].title.set_text(\"Lymph Contour Mask\")\n",
    "    axes[5].imshow(new_data[:, :, 7])\n",
    "    axes[5].title.set_text(\"Mono Mask\")\n",
    "    axes[6].imshow(new_data[:, :, 8])\n",
    "    axes[6].title.set_text(\"Mono Contour Mask\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-01-07|17:00:44.284| [WARNING] Metadata: Falling back to TIFF resolution tag for microns-per-pixel (MPP).\n",
      "|2025-01-07|17:00:44.285| [WARNING] Metadata: Objective power inferred from microns-per-pixel (MPP).\n",
      "|2025-01-07|17:00:44.286| [WARNING] Metadata: Falling back to TIFF resolution tag for microns-per-pixel (MPP).\n",
      "|2025-01-07|17:00:44.287| [WARNING] Metadata: Objective power inferred from microns-per-pixel (MPP).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97536 89600] [97536 89600]\n",
      "{'objective_power': 40.0, 'slide_dimensions': (97536, 89600), 'level_count': 9, 'level_dimensions': ((97536, 89600), (48768, 44800), (24384, 22400), (12192, 11200), (6096, 5600), (3048, 2800), (1524, 1400), (762, 700), (381, 350)), 'level_downsamples': [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0], 'vendor': 'generic-tiff', 'mpp': (0.24199718615086688, 0.24199718615086688), 'file_path': PosixPath('/home/u1910100/Documents/Monkey/test/input/images/tissue-mask/A_P000002_mask.tif'), 'axes': 'YXS'}\n"
     ]
    }
   ],
   "source": [
    "from tiatoolbox.wsicore.wsireader import WSIReader\n",
    "\n",
    "wsi_path = \"/home/u1910100/Documents/Monkey/test/input/images/kidney-transplant-biopsy-wsi-pas/A_P000002_PAS_CPG.tif\"\n",
    "mask_path = \"/home/u1910100/Documents/Monkey/test/input/images/tissue-mask/A_P000002_mask.tif\"\n",
    "\n",
    "wsi_reader = WSIReader.open(wsi_path)\n",
    "mask_reader = WSIReader.open(mask_path)\n",
    "\n",
    "wsi_shape = wsi_reader.slide_dimensions(resolution=0, units='level')\n",
    "mask_shape = mask_reader.slide_dimensions(resolution=0, units='level')\n",
    "\n",
    "print(wsi_shape, mask_shape)\n",
    "\n",
    "print(mask_reader.info.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
