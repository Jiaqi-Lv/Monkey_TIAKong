{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A place to test random stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monkey.model.classification_model.efficientnet_b0 import (\n",
    "    EfficientNet_B0,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monkey.model.utils import (\n",
    "    get_classification_metrics,\n",
    "    get_activation_function,\n",
    ")\n",
    "from monkey.model.loss_functions import get_loss_function, dice_coeff\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mask = np.zeros(shape=(1, 2, 256, 256), dtype=np.float32)\n",
    "true_mask[0, 0, :, :] = 1\n",
    "true_mask = torch.tensor(\n",
    "    true_mask, dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "# pprint(true_mask)\n",
    "pred_mask = np.zeros(shape=(1, 2, 256, 256), dtype=np.float32)\n",
    "pred_mask[0, 0, :, :] = 1\n",
    "pred_mask[0, 1, :, :] = 1\n",
    "pred_mask = torch.tensor(\n",
    "    pred_mask, dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "dice_loss_fn = get_loss_function(\"Dice\")\n",
    "dice_loss_fn.set_multiclass(True)\n",
    "\n",
    "dice_loss = dice_loss_fn.compute_loss(true_mask, pred_mask)\n",
    "\n",
    "pprint(dice_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conch.open_clip_custom import (\n",
    "    create_model_from_pretrained,\n",
    "    tokenize,\n",
    "    get_tokenizer,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = \"conch_ViT-B-16\"\n",
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "checkpoint_path = \"/home/u1910100/Downloads/pytorch_model.bin\"\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    model_cfg, checkpoint_path, device=device\n",
    ")\n",
    "_ = model.eval()\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "classes = [\"lymphocyte\", \"monocyte\"]\n",
    "prompts = [\n",
    "    \"a PAS stained image of a lymphocyte\",\n",
    "    \"a PAS stained image of a monocyte\",\n",
    "]\n",
    "\n",
    "tokenized_prompts = tokenize(texts=prompts, tokenizer=tokenizer).to(\n",
    "    device\n",
    ")\n",
    "tokenized_prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monkey.data.dataset import get_classification_dataloaders\n",
    "from monkey.config import TrainingIOConfig\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/classification\",\n",
    "    save_dir=\"./\",\n",
    ")\n",
    "IOconfig.set_image_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "IOconfig.set_mask_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "batch_size = 32\n",
    "train_loader, val_loader = get_classification_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=1,\n",
    "    batch_size=batch_size,\n",
    "    do_augmentation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_list = []\n",
    "true_labels_list = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    file_ids = data[\"id\"]\n",
    "\n",
    "    images, true_labels = (\n",
    "        data[\"image\"].cuda().float(),\n",
    "        data[\"label\"].cpu().tolist(),\n",
    "    )\n",
    "\n",
    "    true_labels_list.extend(true_labels)\n",
    "    pred_probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        image_embedings = model.encode_image(images)\n",
    "        text_embedings = model.encode_text(tokenized_prompts)\n",
    "        sim_scores = (\n",
    "            (\n",
    "                image_embedings\n",
    "                @ text_embedings.T\n",
    "                * model.logit_scale.exp()\n",
    "            )\n",
    "            .softmax(dim=-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "        pred_probs_list.extend(sim_scores[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monkey.model.utils import get_classification_metrics\n",
    "\n",
    "pred_probs_list = np.array(pred_probs_list)\n",
    "true_labels_list = np.array(true_labels_list)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(\n",
    "    true_labels_list, pred_probs_list\n",
    ")\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(\n",
    "    fpr=fpr,\n",
    "    tpr=tpr,\n",
    "    roc_auc=roc_auc,\n",
    "    estimator_name=\"cell classifier\",\n",
    ")\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "thresh = 0.5\n",
    "pred_labels_list = np.where(pred_probs_list > thresh, 1, 0)\n",
    "scores = get_classification_metrics(\n",
    "    true_labels_list, pred_labels_list\n",
    ")\n",
    "print(scores)\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    true_labels_list,\n",
    "    pred_labels_list,\n",
    "    display_labels=[\"lymphocyte\", \"monocyte\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_loader))\n",
    "images = data[\"image\"].to(\"cuda\").float()\n",
    "print(data[\"label\"])\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image_embedings = model.encode_image(images)\n",
    "    text_embedings = model.encode_text(tokenized_prompts)\n",
    "    sim_scores = (\n",
    "        (image_embedings @ text_embedings.T * model.logit_scale.exp())\n",
    "        .softmax(dim=-1)\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "pred_class = sim_scores.argmax()\n",
    "print(pred_class)\n",
    "print(sim_scores)\n",
    "print(sim_scores[:, 1])\n",
    "# print(\"Predicted class:\", classes[sim_scores.argmax()])\n",
    "# print(\n",
    "#     \"Normalized similarity scores:\",\n",
    "#     [\n",
    "#         f\"{cls}: {score:.3f}\"\n",
    "#         for cls, score in zip(classes, sim_scores[0])\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CellViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monkey.model.cellvit.cellvit import CellViT256\n",
    "\n",
    "model_path = \"/home/u1910100/Downloads/CellViT-256-x40.pth\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model_checkpoint = torch.load(model_path)\n",
    "print(model_checkpoint[\"arch\"])\n",
    "print(model_checkpoint[\"config\"])\n",
    "\n",
    "model = CellViT256(\n",
    "    model256_path=None,\n",
    "    num_nuclei_classes=6,\n",
    "    num_tissue_classes=19,\n",
    "    regression_loss=False,\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_checkpoint[\"model_state_dict\"])\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from monkey.data.data_utils import erode_mask\n",
    "\n",
    "\n",
    "def binary_to_color(mask):\n",
    "    rgb = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    rgb[:, :, 0] = np.where(mask == 1, 255, 0)\n",
    "    rgb[:, :, 1] = np.where(mask == 2, 255, 0)\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def instance_map_to_contour(instance_map):\n",
    "\n",
    "    binary_mask = np.zeros(shape=(instance_map.shape), dtype=np.uint8)\n",
    "    binary_mask = np.where(instance_map > 0, 1, 0).astype(np.uint8)\n",
    "    binary_mask_eroded = erode_mask(binary_mask, 3)\n",
    "    binary_mask_eroded = (binary_mask_eroded > 0).astype(np.uint8)\n",
    "\n",
    "    contour_map = binary_mask - binary_mask_eroded\n",
    "    contour_map = (contour_map > 0).astype(np.uint8)\n",
    "\n",
    "    return contour_map\n",
    "\n",
    "\n",
    "nuclick_dir = \"/home/u1910100/Documents/Monkey/patches_256/annotations/nuclick_hovernext\"\n",
    "files = os.listdir(nuclick_dir)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for fn in files:\n",
    "    data_path = os.path.join(nuclick_dir, fn)\n",
    "    data = np.load(data_path)\n",
    "\n",
    "    image = data[:, :, 0:3]\n",
    "\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    instance_map = data[:, :, 3]\n",
    "\n",
    "    contour_map = instance_map_to_contour(instance_map)\n",
    "\n",
    "    class_map = data[:, :, 4]\n",
    "    class_map_rgb = binary_to_color(class_map)\n",
    "\n",
    "    fix, axes = plt.subplots(1, 4, figsize=(14, 12))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"RGB\")\n",
    "    axes[1].imshow(instance_map)\n",
    "    axes[1].set_title(\"Instance map\")\n",
    "    axes[2].imshow(class_map_rgb)\n",
    "    axes[2].set_title(\"Class Map\")\n",
    "    axes[3].imshow(contour_map, cmap=\"gray\")\n",
    "    axes[3].set_title(\"Contour\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "from torchvision.models.efficientnet import (\n",
    "    efficientnet_b0,\n",
    ")\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    EfficientUnet_MBConv,\n",
    "    EfficientUnet_MBConv_Multihead,\n",
    ")\n",
    "from torchinfo import summary\n",
    "\n",
    "encoder = efficientnet_b0()\n",
    "encoder = encoder.features\n",
    "\n",
    "model_2 = EfficientUnet_MBConv_Multihead(\n",
    "    encoder, num_heads=2, decoders_out_channels=[2, 1]\n",
    ")\n",
    "model_2.eval()\n",
    "summary(model_2, input_size=(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_input = torch.ones(size=(1, 3, 256, 256))\n",
    "\n",
    "    model_2_out = model_2(test_input)\n",
    "    print(model_2_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
