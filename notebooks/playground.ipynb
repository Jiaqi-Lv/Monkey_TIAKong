{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A place to test random stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monkey.model.utils import (\n",
    "    get_classification_metrics,\n",
    "    get_activation_function,\n",
    ")\n",
    "from monkey.model.loss_functions import get_loss_function, dice_coeff\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mask = np.zeros(shape=(1, 1, 256, 256), dtype=np.float32)\n",
    "true_mask[0, 0, :, :] = 1\n",
    "true_mask = torch.tensor(\n",
    "    true_mask, dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "# pprint(true_mask)\n",
    "pred_mask = np.zeros(shape=(1, 1, 256, 256), dtype=np.float32)\n",
    "pred_mask[0, 0, :, :] = 1\n",
    "# pred_mask[0, 1, :, :] = 0\n",
    "pred_mask = torch.tensor(\n",
    "    pred_mask, dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "dice_loss_fn = get_loss_function(\"Dice\")\n",
    "dice_loss_fn.set_multiclass(True)\n",
    "\n",
    "dice_loss = dice_loss_fn.compute_loss(true_mask, pred_mask)\n",
    "\n",
    "pprint(dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.rand(size=(1, 3, 256, 256))\n",
    "print(out.shape)\n",
    "\n",
    "pred = torch.softmax(out, dim=1)\n",
    "print(pred.shape)\n",
    "\n",
    "class_pred = torch.argmax(pred, dim=1, keepdim=True)\n",
    "print(class_pred.shape)\n",
    "\n",
    "background = torch.where(class_pred == 0, 1.0, 0.0)\n",
    "print(background.shape, background.dtype)\n",
    "\n",
    "print(class_pred)\n",
    "print(background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conch.open_clip_custom import (\n",
    "    create_model_from_pretrained,\n",
    "    tokenize,\n",
    "    get_tokenizer,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = \"conch_ViT-B-16\"\n",
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "checkpoint_path = \"/home/u1910100/Downloads/pytorch_model.bin\"\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    model_cfg, checkpoint_path, device=device\n",
    ")\n",
    "_ = model.eval()\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "classes = [\"lymphocyte\", \"monocyte\"]\n",
    "prompts = [\n",
    "    \"a PAS stained image of a lymphocyte\",\n",
    "    \"a PAS stained image of a monocyte\",\n",
    "]\n",
    "\n",
    "tokenized_prompts = tokenize(texts=prompts, tokenizer=tokenizer).to(\n",
    "    device\n",
    ")\n",
    "tokenized_prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monkey.data.dataset import get_classification_dataloaders\n",
    "from monkey.config import TrainingIOConfig\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/classification\",\n",
    "    save_dir=\"./\",\n",
    ")\n",
    "IOconfig.set_image_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "IOconfig.set_mask_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "batch_size = 32\n",
    "train_loader, val_loader = get_classification_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=1,\n",
    "    batch_size=batch_size,\n",
    "    do_augmentation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_list = []\n",
    "true_labels_list = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    file_ids = data[\"id\"]\n",
    "\n",
    "    images, true_labels = (\n",
    "        data[\"image\"].cuda().float(),\n",
    "        data[\"label\"].cpu().tolist(),\n",
    "    )\n",
    "\n",
    "    true_labels_list.extend(true_labels)\n",
    "    pred_probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        image_embedings = model.encode_image(images)\n",
    "        text_embedings = model.encode_text(tokenized_prompts)\n",
    "        sim_scores = (\n",
    "            (\n",
    "                image_embedings\n",
    "                @ text_embedings.T\n",
    "                * model.logit_scale.exp()\n",
    "            )\n",
    "            .softmax(dim=-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "        pred_probs_list.extend(sim_scores[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monkey.model.utils import get_classification_metrics\n",
    "\n",
    "pred_probs_list = np.array(pred_probs_list)\n",
    "true_labels_list = np.array(true_labels_list)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(\n",
    "    true_labels_list, pred_probs_list\n",
    ")\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(\n",
    "    fpr=fpr,\n",
    "    tpr=tpr,\n",
    "    roc_auc=roc_auc,\n",
    "    estimator_name=\"cell classifier\",\n",
    ")\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "thresh = 0.5\n",
    "pred_labels_list = np.where(pred_probs_list > thresh, 1, 0)\n",
    "scores = get_classification_metrics(\n",
    "    true_labels_list, pred_labels_list\n",
    ")\n",
    "print(scores)\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    true_labels_list,\n",
    "    pred_labels_list,\n",
    "    display_labels=[\"lymphocyte\", \"monocyte\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_loader))\n",
    "images = data[\"image\"].to(\"cuda\").float()\n",
    "print(data[\"label\"])\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image_embedings = model.encode_image(images)\n",
    "    text_embedings = model.encode_text(tokenized_prompts)\n",
    "    sim_scores = (\n",
    "        (image_embedings @ text_embedings.T * model.logit_scale.exp())\n",
    "        .softmax(dim=-1)\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "pred_class = sim_scores.argmax()\n",
    "print(pred_class)\n",
    "print(sim_scores)\n",
    "print(sim_scores[:, 1])\n",
    "# print(\"Predicted class:\", classes[sim_scores.argmax()])\n",
    "# print(\n",
    "#     \"Normalized similarity scores:\",\n",
    "#     [\n",
    "#         f\"{cls}: {score:.3f}\"\n",
    "#         for cls, score in zip(classes, sim_scores[0])\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CellViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monkey.model.cellvit.cellvit import CellViT256\n",
    "\n",
    "model_path = \"/home/u1910100/Downloads/CellViT-256-x40.pth\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model_checkpoint = torch.load(model_path)\n",
    "print(model_checkpoint[\"arch\"])\n",
    "print(model_checkpoint[\"config\"])\n",
    "\n",
    "model = CellViT256(\n",
    "    model256_path=None,\n",
    "    num_nuclei_classes=6,\n",
    "    num_tissue_classes=19,\n",
    "    regression_loss=False,\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_checkpoint[\"model_state_dict\"])\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapDe Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from scipy import ndimage, signal\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from monkey.data.data_utils import erode_mask, generate_regression_map\n",
    "import cv2\n",
    "from skimage import draw\n",
    "\n",
    "cell_mask = np.zeros(shape=(256, 256), dtype=np.uint8)\n",
    "rr, cc = draw.ellipse(100, 100, 1, 1, shape=cell_mask.shape)\n",
    "# rr, cc = 100, 100\n",
    "cell_mask[rr, cc] = 1\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def gauss_2d_filter(shape=(11, 11)):\n",
    "    sigma = int((shape[0] - 1) / 6)\n",
    "    m, n = [(ss - 1.0) / 2.0 for ss in shape]\n",
    "    y, x = np.ogrid[-m : m + 1, -n : n + 1]\n",
    "    h = np.exp(-(x * x + y * y) / (2.0 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "\n",
    "    h = h / (h[int(m), int(n)])\n",
    "    return h\n",
    "\n",
    "\n",
    "dist_filter = gauss_2d_filter(shape=(17, 17))\n",
    "plt.imshow(dist_filter)\n",
    "plt.show()\n",
    "# cell_mask = generate_regression_map(cell_mask, d_thresh=5, alpha=0.5, scale=1)\n",
    "# plt.imshow(cell_mask)\n",
    "# plt.show()\n",
    "\n",
    "cell_mask = signal.convolve2d(cell_mask, dist_filter)\n",
    "print(np.max(cell_mask))\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multihead Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "from torchvision.models.efficientnet import (\n",
    "    efficientnet_b0,\n",
    ")\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    get_multihead_efficientunet,\n",
    ")\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "model = get_multihead_efficientunet(\n",
    "    out_channels=[2, 1], pretrained=True\n",
    ")\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "summary(model, input_size=(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_input = torch.ones(\n",
    "        size=(1, 3, 256, 256), dtype=torch.float, device=\"cuda\"\n",
    "    )\n",
    "    model_out = model(test_input)\n",
    "    pprint(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapDe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from monkey.model.mapde.model import MapDe\n",
    "from monkey.data.dataset import get_detection_dataloaders\n",
    "from monkey.config import TrainingIOConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monkey.data.data_utils import imagenet_denormalise\n",
    "import torch\n",
    "\n",
    "use_nuclick_masks = False\n",
    "batch_size = 1\n",
    "module = \"detection\"\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    "    save_dir=\"./\",\n",
    ")\n",
    "\n",
    "\n",
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=5,\n",
    "    dataset_name=\"detection\",\n",
    "    batch_size=batch_size,\n",
    "    disk_radius=1,\n",
    "    regression_map=False,\n",
    "    do_augmentation=True,\n",
    "    module=module,\n",
    "    use_nuclick_masks=use_nuclick_masks,\n",
    "    include_background_channel=False,\n",
    ")\n",
    "\n",
    "\n",
    "model = MapDe(3, 30, 50, num_classes=1, filter_size=31)\n",
    "model.eval()\n",
    "# print(model)\n",
    "test_input = torch.ones(size=(4, 3, 252, 252), dtype=torch.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "print(f\"output size = {out.size()}\")\n",
    "# print(torch.max(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 18))\n",
    "\n",
    "image = data[\"image\"][0].numpy()\n",
    "image = np.moveaxis(image, 0, 2)\n",
    "image = imagenet_denormalise(image)\n",
    "axes[0].imshow(image)\n",
    "\n",
    "mask = data[\"mask\"]\n",
    "mask_filtered = model.blur_cell_points(mask)\n",
    "\n",
    "\n",
    "axes[1].imshow(image, alpha=0.5)\n",
    "mask_filtered_numpy = mask_filtered.numpy()\n",
    "axes[1].imshow(mask_filtered_numpy[0][0], alpha=0.5)\n",
    "axes[2].imshow(mask_filtered_numpy[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logits = torch.rand(size=(2, 3, 252, 252))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(test_logits)\n",
    "    probs = model.logits_to_probs(logits)\n",
    "print(logits)\n",
    "\n",
    "out_masks = model.postproc(logits)\n",
    "out_masks = out_masks[:, np.newaxis, :, :]\n",
    "out_masks = model.blur_cell_points(out_masks)\n",
    "\n",
    "logits = logits.numpy(force=True)\n",
    "probs = probs.numpy(force=True)\n",
    "\n",
    "\n",
    "plt.imshow(logits[0][0])\n",
    "plt.show()\n",
    "print(np.max(logits[0][0]))\n",
    "\n",
    "plt.imshow(probs[0][0])\n",
    "plt.show()\n",
    "\n",
    "# print(np.max(logits))\n",
    "plt.imshow(out_masks[0][0])\n",
    "plt.show()\n",
    "\n",
    "import skimage\n",
    "\n",
    "inflamm_labels = skimage.measure.label(out_masks[0][0])\n",
    "inflamm_stats = skimage.measure.regionprops(\n",
    "    inflamm_labels, intensity_image=probs[0][0]\n",
    ")\n",
    "for region in inflamm_stats:\n",
    "    centroid = region[\"centroid\"]\n",
    "\n",
    "    c, r, confidence = (\n",
    "        centroid[1],\n",
    "        centroid[0],\n",
    "        region[\"mean_intensity\"],\n",
    "    )\n",
    "    print(c, r, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoverNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40192083\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from monkey.model.hovernext.model import get_custom_hovernext\n",
    "\n",
    "model = get_custom_hovernext(pretrained=True)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "model.train()\n",
    "\n",
    "model_parameters = filter(\n",
    "    lambda p: p.requires_grad, model.parameters()\n",
    ")\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test_input = torch.ones(size=(1, 3, 256, 256))\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
