{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A place to test random stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monkey.model.utils import (\n",
    "    get_classification_metrics,\n",
    "    get_activation_function,\n",
    ")\n",
    "from monkey.model.loss_functions import get_loss_function, dice_coeff\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mask = torch.zeros(size=(1, 1, 256, 256))\n",
    "true_mask[0, 0, 0, 0] = 0.5\n",
    "print(true_mask)\n",
    "pred_mask = torch.zeros(size=(1, 1, 256, 256))\n",
    "print(pred_mask)\n",
    "true_mask[0, 0, 0, 0] = 0.5\n",
    "loss_fn = get_loss_function(\"Jaccard_Loss\")\n",
    "loss = loss_fn.compute_loss(pred_mask, true_mask)\n",
    "pprint(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.zeros(size=(16, 3, 256, 256))\n",
    "# test[0,0,0,0] = 1\n",
    "\n",
    "no_pos = torch.count_nonzero(test).item()\n",
    "no_negs = torch.numel(test) - no_pos\n",
    "print(no_negs, no_pos)\n",
    "# weight = no_negs / no_pos\n",
    "# print(weight)\n",
    "eps = 1e-6\n",
    "weight_0 = torch.numel(test) / (2 * no_negs + eps)\n",
    "weight_1 = torch.numel(test) / (2 * no_pos + eps)\n",
    "\n",
    "print(weight_0)\n",
    "print(weight_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conch.open_clip_custom import (\n",
    "    create_model_from_pretrained,\n",
    "    tokenize,\n",
    "    get_tokenizer,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = \"conch_ViT-B-16\"\n",
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "checkpoint_path = \"/home/u1910100/Downloads/pytorch_model.bin\"\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    model_cfg, checkpoint_path, device=device\n",
    ")\n",
    "_ = model.eval()\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "classes = [\"lymphocyte\", \"monocyte\"]\n",
    "prompts = [\n",
    "    \"a PAS stained image of a lymphocyte\",\n",
    "    \"a PAS stained image of a monocyte\",\n",
    "]\n",
    "\n",
    "tokenized_prompts = tokenize(texts=prompts, tokenizer=tokenizer).to(\n",
    "    device\n",
    ")\n",
    "tokenized_prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monkey.data.dataset import get_classification_dataloaders\n",
    "from monkey.config import TrainingIOConfig\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/classification\",\n",
    "    save_dir=\"./\",\n",
    ")\n",
    "IOconfig.set_image_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "IOconfig.set_mask_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/classification/patches\"\n",
    ")\n",
    "batch_size = 32\n",
    "train_loader, val_loader = get_classification_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=1,\n",
    "    batch_size=batch_size,\n",
    "    do_augmentation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_list = []\n",
    "true_labels_list = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    file_ids = data[\"id\"]\n",
    "\n",
    "    images, true_labels = (\n",
    "        data[\"image\"].cuda().float(),\n",
    "        data[\"label\"].cpu().tolist(),\n",
    "    )\n",
    "\n",
    "    true_labels_list.extend(true_labels)\n",
    "    pred_probs = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        image_embedings = model.encode_image(images)\n",
    "        text_embedings = model.encode_text(tokenized_prompts)\n",
    "        sim_scores = (\n",
    "            (\n",
    "                image_embedings\n",
    "                @ text_embedings.T\n",
    "                * model.logit_scale.exp()\n",
    "            )\n",
    "            .softmax(dim=-1)\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "        pred_probs_list.extend(sim_scores[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monkey.model.utils import get_classification_metrics\n",
    "\n",
    "pred_probs_list = np.array(pred_probs_list)\n",
    "true_labels_list = np.array(true_labels_list)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(\n",
    "    true_labels_list, pred_probs_list\n",
    ")\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(\n",
    "    fpr=fpr,\n",
    "    tpr=tpr,\n",
    "    roc_auc=roc_auc,\n",
    "    estimator_name=\"cell classifier\",\n",
    ")\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "thresh = 0.5\n",
    "pred_labels_list = np.where(pred_probs_list > thresh, 1, 0)\n",
    "scores = get_classification_metrics(\n",
    "    true_labels_list, pred_labels_list\n",
    ")\n",
    "print(scores)\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    true_labels_list,\n",
    "    pred_labels_list,\n",
    "    display_labels=[\"lymphocyte\", \"monocyte\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_loader))\n",
    "images = data[\"image\"].to(\"cuda\").float()\n",
    "print(data[\"label\"])\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image_embedings = model.encode_image(images)\n",
    "    text_embedings = model.encode_text(tokenized_prompts)\n",
    "    sim_scores = (\n",
    "        (image_embedings @ text_embedings.T * model.logit_scale.exp())\n",
    "        .softmax(dim=-1)\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "pred_class = sim_scores.argmax()\n",
    "print(pred_class)\n",
    "print(sim_scores)\n",
    "print(sim_scores[:, 1])\n",
    "# print(\"Predicted class:\", classes[sim_scores.argmax()])\n",
    "# print(\n",
    "#     \"Normalized similarity scores:\",\n",
    "#     [\n",
    "#         f\"{cls}: {score:.3f}\"\n",
    "#         for cls, score in zip(classes, sim_scores[0])\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CellViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "from monkey.model.cellvit.cellvit import CellViT256, CellVit256_Unet\n",
    "\n",
    "model_path = \"/home/u1910100/Downloads/HIPT_vit256_small_dino.pth\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model = CellVit256_Unet(num_decoders=3)\n",
    "\n",
    "model.load_pretrained_encoder(model_path)\n",
    "\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "test = torch.rand(size=(4, 3, 256, 256))\n",
    "out = model(test)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapDe Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from scipy import ndimage, signal\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from monkey.data.data_utils import erode_mask, generate_regression_map\n",
    "import cv2\n",
    "from skimage import draw\n",
    "\n",
    "cell_mask = np.zeros(shape=(256, 256), dtype=np.uint8)\n",
    "rr, cc = draw.ellipse(100, 100, 1, 1, shape=cell_mask.shape)\n",
    "# rr, cc = 100, 100\n",
    "cell_mask[rr, cc] = 1\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def gauss_2d_filter(shape=(11, 11)):\n",
    "    sigma = int((shape[0] - 1) / 6)\n",
    "    m, n = [(ss - 1.0) / 2.0 for ss in shape]\n",
    "    y, x = np.ogrid[-m : m + 1, -n : n + 1]\n",
    "    h = np.exp(-(x * x + y * y) / (2.0 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "\n",
    "    h = h / (h[int(m), int(n)])\n",
    "    return h\n",
    "\n",
    "\n",
    "dist_filter = gauss_2d_filter(shape=(17, 17))\n",
    "plt.imshow(dist_filter)\n",
    "plt.show()\n",
    "# cell_mask = generate_regression_map(cell_mask, d_thresh=5, alpha=0.5, scale=1)\n",
    "# plt.imshow(cell_mask)\n",
    "# plt.show()\n",
    "\n",
    "cell_mask = signal.convolve2d(cell_mask, dist_filter)\n",
    "print(np.max(cell_mask))\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multihead Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "from torchvision.models.efficientnet import (\n",
    "    efficientnet_b0,\n",
    ")\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    get_multihead_efficientunet,\n",
    ")\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "model = get_multihead_efficientunet(\n",
    "    out_channels=[2, 1], pretrained=True\n",
    ")\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "summary(model, input_size=(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_input = torch.ones(\n",
    "        size=(1, 3, 256, 256), dtype=torch.float, device=\"cuda\"\n",
    "    )\n",
    "    model_out = model(test_input)\n",
    "    pprint(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapDe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from monkey.model.mapde.model import MapDe\n",
    "from monkey.data.dataset import get_detection_dataloaders\n",
    "from monkey.config import TrainingIOConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monkey.data.data_utils import imagenet_denormalise\n",
    "import torch\n",
    "\n",
    "use_nuclick_masks = False\n",
    "batch_size = 1\n",
    "module = \"detection\"\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    "    save_dir=\"./\",\n",
    ")\n",
    "\n",
    "\n",
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=5,\n",
    "    dataset_name=\"detection\",\n",
    "    batch_size=batch_size,\n",
    "    disk_radius=1,\n",
    "    regression_map=False,\n",
    "    do_augmentation=True,\n",
    "    module=module,\n",
    "    use_nuclick_masks=use_nuclick_masks,\n",
    "    include_background_channel=False,\n",
    ")\n",
    "\n",
    "\n",
    "model = MapDe(3, 30, 50, num_classes=1, filter_size=31)\n",
    "model.eval()\n",
    "# print(model)\n",
    "test_input = torch.ones(size=(4, 3, 252, 252), dtype=torch.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "print(f\"output size = {out.size()}\")\n",
    "# print(torch.max(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 18))\n",
    "\n",
    "image = data[\"image\"][0].numpy()\n",
    "image = np.moveaxis(image, 0, 2)\n",
    "image = imagenet_denormalise(image)\n",
    "axes[0].imshow(image)\n",
    "\n",
    "mask = data[\"mask\"]\n",
    "mask_filtered = model.blur_cell_points(mask)\n",
    "\n",
    "\n",
    "axes[1].imshow(image, alpha=0.5)\n",
    "mask_filtered_numpy = mask_filtered.numpy()\n",
    "axes[1].imshow(mask_filtered_numpy[0][0], alpha=0.5)\n",
    "axes[2].imshow(mask_filtered_numpy[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logits = torch.rand(size=(2, 3, 252, 252))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(test_logits)\n",
    "    probs = model.logits_to_probs(logits)\n",
    "print(logits)\n",
    "\n",
    "out_masks = model.postproc(logits)\n",
    "out_masks = out_masks[:, np.newaxis, :, :]\n",
    "out_masks = model.blur_cell_points(out_masks)\n",
    "\n",
    "logits = logits.numpy(force=True)\n",
    "probs = probs.numpy(force=True)\n",
    "\n",
    "\n",
    "plt.imshow(logits[0][0])\n",
    "plt.show()\n",
    "print(np.max(logits[0][0]))\n",
    "\n",
    "plt.imshow(probs[0][0])\n",
    "plt.show()\n",
    "\n",
    "# print(np.max(logits))\n",
    "plt.imshow(out_masks[0][0])\n",
    "plt.show()\n",
    "\n",
    "import skimage\n",
    "\n",
    "inflamm_labels = skimage.measure.label(out_masks[0][0])\n",
    "inflamm_stats = skimage.measure.regionprops(\n",
    "    inflamm_labels, intensity_image=probs[0][0]\n",
    ")\n",
    "for region in inflamm_stats:\n",
    "    centroid = region[\"centroid\"]\n",
    "\n",
    "    c, r, confidence = (\n",
    "        centroid[1],\n",
    "        centroid[0],\n",
    "        region[\"mean_intensity\"],\n",
    "    )\n",
    "    print(c, r, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoverNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from monkey.model.hovernext.model import (\n",
    "    get_custom_hovernext,\n",
    "    get_convnext_unet,\n",
    "    get_timm_encoder,\n",
    "    load_encoder_weights,\n",
    ")\n",
    "\n",
    "model = get_custom_hovernext(\n",
    "    enc=\"tf_efficientnetv2_s.in21k\",\n",
    "    pretrained=False,\n",
    "    num_heads=3,\n",
    "    decoders_out_channels=[1, 1, 1],\n",
    ")\n",
    "# model = get_convnext_unet(\n",
    "#     out_classes=2, use_batchnorm=True, attention_type=\"scse\"\n",
    "# )\n",
    "# checkpoint_path = \"/home/u1910100/Downloads/lizard_convnextv2_large/train/best_model\"\n",
    "# model = load_encoder_weights(model, checkpoint_path)\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "pprint(summary(model, input_size=(8, 3, 256, 256)))\n",
    "pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "test_input = torch.ones(\n",
    "    size=(1, 3, 256, 256), dtype=torch.float, device=\"cuda\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pannuke Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from monkey.data.data_utils import (\n",
    "    generate_regression_map,\n",
    "    dilate_mask,\n",
    "    load_image,\n",
    "    load_mask,\n",
    ")\n",
    "from monkey.data.dataset import class_mask_to_multichannel_mask\n",
    "\n",
    "cell_mask = np.zeros(shape=(256, 256), dtype=np.uint8)\n",
    "cell_mask[100, 100] = 1\n",
    "\n",
    "cell_mask = dilate_mask(cell_mask, 3)\n",
    "\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()\n",
    "\n",
    "cell_mask = generate_regression_map(\n",
    "    cell_mask, d_thresh=7, alpha=3, scale=1\n",
    ")\n",
    "plt.imshow(cell_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = \"/home/u1910100/Documents/Monkey/patches_256/annotations/masks/C_P000029_18592_66528_18848_66784.npy\"\n",
    "mask = np.load(mask_path)\n",
    "class_mask = class_mask_to_multichannel_mask(mask)\n",
    "\n",
    "plt.imshow(class_mask[0])\n",
    "plt.show()\n",
    "plt.imshow(class_mask[1])\n",
    "plt.show()\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "dist = ndi.distance_transform_edt(class_mask[0] == 0)\n",
    "M = (np.exp(3 * (1 - dist / 7)) - 1) / (np.exp(3) - 1)\n",
    "M[M < 0] = 0\n",
    "M *= 1\n",
    "\n",
    "plt.imshow(M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from strong_augment import StrongAugment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trnsf = T.Compose(\n",
    "    [\n",
    "        StrongAugment(\n",
    "            operations=[2, 3, 4], probabilites=[0.5, 0.3, 0.2]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the images\n",
    "image = np.load(\n",
    "    \"/home/u1910100/Documents/Monkey/patches_256/images/A_P000001_9632_87360_9888_87616.npy\"\n",
    ")\n",
    "aug_image = trnsf(image)\n",
    "\n",
    "# Create a subplot with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Display the original image\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# image = image / 255.0\n",
    "# Display the augmented image\n",
    "axes[1].imshow(\n",
    "    aug_image\n",
    ")  # Permute the dimensions for correct display\n",
    "axes[1].set_title(\"Augmented Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from monkey.model.hovernext.modified_self_attention import (\n",
    "    get_model,\n",
    "    ModifiedSelfAttention,\n",
    ")\n",
    "\n",
    "model = get_model(\n",
    "    enc=\"tf_efficientnetv2_s\",\n",
    "    pretrained=False,\n",
    ")\n",
    "pprint(summary(model, input_size=(1, 3, 256, 256)))\n",
    "\n",
    "test_input = torch.ones(\n",
    "    size=(1, 3, 256, 256), dtype=torch.float, device=\"cuda\"\n",
    ")\n",
    "with torch.no_grad():\n",
    "    out = model(test_input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u1910100/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Conv2d: 1, Conv2d: 1, Conv2d: 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/GitHub/Monkey_TIAKong/notebooks/../monkey/model/hovernext/modified_self_attention.py:215\u001b[0m, in \u001b[0;36mModifiedSelfAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Getting the weighted sum of values\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# (batch_size, height*width, out_channels)\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m out \u001b[38;5;241m=\u001b[39m (\u001b[43mattention\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproj_value\u001b[49m)\n\u001b[1;32m    216\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels, height, width)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (65536) at non-singleton dimension 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmonkey\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhovernext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodified_self_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     get_model,\n\u001b[1;32m      9\u001b[0m     ModifiedSelfAttention\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m attention_module \u001b[38;5;241m=\u001b[39m ModifiedSelfAttention()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tiatoolbox/lib/python3.11/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Conv2d: 1, Conv2d: 1, Conv2d: 1]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from monkey.model.hovernext.modified_self_attention import (\n",
    "    get_model,\n",
    "    ModifiedSelfAttention,\n",
    ")\n",
    "\n",
    "attention_module = ModifiedSelfAttention()\n",
    "print(summary(attention_module, input_size=(1, 192, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
