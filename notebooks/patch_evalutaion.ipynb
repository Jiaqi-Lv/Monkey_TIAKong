{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    get_efficientunet_b0_MBConv,\n",
    ")\n",
    "import skimage\n",
    "import cv2\n",
    "import torch\n",
    "from monkey.config import TrainingIOConfig\n",
    "from monkey.data.dataset import get_detection_dataloaders\n",
    "from monkey.data.data_utils import (\n",
    "    imagenet_denormalise,\n",
    "    load_json_annotation,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from monkey.model.utils import (\n",
    "    get_patch_F1_score,\n",
    "    get_patch_F1_score_batch,\n",
    "    get_multiclass_patch_F1_score_batch,\n",
    ")\n",
    "from skimage.morphology import remove_small_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_mask(mask, size=3):\n",
    "    kernel = cv2.getStructuringElement(\n",
    "        cv2.MORPH_ELLIPSE, (size, size)\n",
    "    )\n",
    "    if mask.ndim == 4:\n",
    "        for i in range(mask.shape[0]):\n",
    "            for j in range(mask.shape[1]):\n",
    "                mask[i, j, :, :] = cv2.erode(\n",
    "                    mask[i, j, :, :], kernel, iterations=1\n",
    "                )\n",
    "    else:\n",
    "        mask = cv2.erode(mask, kernel, iterations=1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def morphological_post_processing(mask, size=3):\n",
    "    kernel = cv2.getStructuringElement(\n",
    "        cv2.MORPH_ELLIPSE, (size, size)\n",
    "    )\n",
    "    if mask.ndim == 4:\n",
    "        for i in range(mask.shape[0]):\n",
    "            for j in range(mask.shape[1]):\n",
    "                mask[i, j, :, :] = cv2.morphologyEx(\n",
    "                    mask[i, j, :, :], cv2.MORPH_OPEN, kernel\n",
    "                )\n",
    "                mask[i, j, :, :] = cv2.morphologyEx(\n",
    "                    mask[i, j, :, :], cv2.MORPH_CLOSE, kernel\n",
    "                )\n",
    "    else:\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def filter_objects_by_size(label_image, min_size=0, max_size=None):\n",
    "    small_removed = remove_small_objects(label_image, min_size)\n",
    "    if max_size is not None:\n",
    "        mid_removed = remove_small_objects(small_removed, max_size)\n",
    "        large_removed = label_image - mid_removed\n",
    "        return large_removed\n",
    "    else:\n",
    "        return small_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Detection (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_efficientunet_b0_MBConv(pretrained=False)\n",
    "# model = smp.Unet(\n",
    "#     encoder_name=\"mit_b5\",\n",
    "#     encoder_weights=None,\n",
    "#     decoder_attention_type=\"scse\",\n",
    "#     in_channels=3,\n",
    "#     classes=1,\n",
    "# )\n",
    "\n",
    "val_fold = 5\n",
    "\n",
    "checkpoint_path = f\"/home/u1910100/Documents/Monkey/runs/detection/efficientunetb0_seg/fold_{val_fold}/epoch_75.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "\n",
    "nuclick_mask = False\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    "    save_dir=f\"./\",\n",
    ")\n",
    "if nuclick_mask:\n",
    "    IOconfig.set_mask_dir(\n",
    "        \"/home/u1910100/Documents/Monkey/patches_256/annotations/nuclick_hovernext\"\n",
    "    )\n",
    "\n",
    "# Get dataloaders for task\n",
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=val_fold,\n",
    "    task=1,\n",
    "    batch_size=32,\n",
    "    disk_radius=11,\n",
    "    do_augmentation=False,\n",
    "    use_nuclick_masks=nuclick_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = [0.1]\n",
    "thresholds = [0, 3, 0.5, 0.7]\n",
    "# thresholds = [0.5]\n",
    "best_thresh = thresholds[0]\n",
    "best_F1 = 0\n",
    "\n",
    "# visualization = False\n",
    "\n",
    "for thresh in thresholds:\n",
    "    print(f\"threshold {thresh}\")\n",
    "    counter = 0\n",
    "    sum_F1 = []\n",
    "    sum_precision = []\n",
    "    sum_recall = []\n",
    "    for data in tqdm(val_loader):\n",
    "        file_ids = data[\"id\"]\n",
    "\n",
    "        images = data[\"image\"].cuda().float()\n",
    "        gt_masks = data[\"mask\"].cuda().float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(images)\n",
    "            out = torch.sigmoid(out)\n",
    "\n",
    "        out_mask = (out > 0.5).float()\n",
    "        out_mask = out_mask.numpy(force=True).astype(np.uint8)\n",
    "        out_mask = erode_mask(out_mask, 3)\n",
    "        out_mask = morphological_post_processing(out_mask, 3)\n",
    "\n",
    "        metrics = get_multiclass_patch_F1_score_batch(\n",
    "            out_mask, gt_masks, out\n",
    "        )\n",
    "        f1, precision, recall = (\n",
    "            metrics[\"F1\"],\n",
    "            metrics[\"Precision\"],\n",
    "            metrics[\"Recall\"],\n",
    "        )\n",
    "\n",
    "        sum_F1.append(f1)\n",
    "        sum_precision.append(precision)\n",
    "        sum_recall.append(recall)\n",
    "\n",
    "    sum_F1 = [x for x in sum_F1 if x is not None]\n",
    "    sum_precision = [x for x in sum_precision if x is not None]\n",
    "    sum_recall = [x for x in sum_recall if x is not None]\n",
    "\n",
    "    print(\"Avg F1 \", np.mean(sum_F1))\n",
    "    print(\"Median F1 \", np.median(sum_F1))\n",
    "    print(\"Avg Precision \", np.mean(sum_precision))\n",
    "    print(\"Avg Recall \", np.mean(sum_recall))\n",
    "\n",
    "    if np.mean(sum_F1) > best_F1:\n",
    "        best_F1 = np.mean(sum_F1)\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(f\"best threshold: {best_thresh}\")\n",
    "print(f\"best F1: {best_F1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=val_fold,\n",
    "    task=1,\n",
    "    batch_size=1,\n",
    "    disk_radius=11,\n",
    "    do_augmentation=False,\n",
    "    module=\"detection\",\n",
    "    use_nuclick_masks=nuclick_mask,\n",
    ")\n",
    "\n",
    "thresh = 0.5\n",
    "\n",
    "counter = 0\n",
    "for data in val_loader:\n",
    "    file_ids = data[\"id\"]\n",
    "    images = data[\"image\"].cuda().float()\n",
    "    gt_masks = data[\"mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(images)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "    out_mask = (out > 0.5).float()\n",
    "    out_mask = out_mask.numpy(force=True).astype(np.uint8)\n",
    "    out_mask = erode_mask(out_mask, 3)\n",
    "    out_mask = morphological_post_processing(out_mask, 3)\n",
    "    # prob = out[0, 0, :, :]\n",
    "\n",
    "    lymphocyte_pred = out_mask[0, 0, :, :]\n",
    "    # pred = np.where(\n",
    "    #     prob > thresh, 1, 0\n",
    "    # ).astype(np.uint8)\n",
    "    # pred = erode_mask(pred, 7)\n",
    "    # pred = filter_objects_by_size(pred, 300, 60000)\n",
    "\n",
    "    image_np = images.numpy(force=True)[0]\n",
    "    gt_mask_np = gt_masks.numpy(force=True)[0, 0]\n",
    "    image_np = np.moveaxis(image_np, 0, 2)\n",
    "    image_np = imagenet_denormalise(image_np)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(8, 18))\n",
    "    axs[0].imshow(image_np)\n",
    "    axs[0].title.set_text(\"Image\")\n",
    "\n",
    "    axs[1].imshow(gt_mask_np, cmap=\"gray\")\n",
    "    axs[1].title.set_text(\"Ground Truth\")\n",
    "\n",
    "    axs[2].imshow(lymphocyte_pred, cmap=\"gray\")\n",
    "    axs[2].title.set_text(\"Pred\")\n",
    "\n",
    "    # axs[3].imshow(prob, cmap='jet')\n",
    "    # axs[3].title.set_text(\"Probs\")\n",
    "\n",
    "    for ax in fig.axes:\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    counter += 1\n",
    "    if counter > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_efficientunet_b0_MBConv(pretrained=False, out_channels=3)\n",
    "val_fold = 1\n",
    "\n",
    "has_background_channel = True\n",
    "\n",
    "checkpoint_path = f\"/home/u1910100/Documents/Monkey/runs/cell_multiclass_det/efficientunetb0_seg_3_channel/fold_{val_fold}/epoch_10.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    "    save_dir=f\"./\",\n",
    ")\n",
    "\n",
    "# Get dataloaders for task\n",
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=val_fold,\n",
    "    task=1,\n",
    "    batch_size=32,\n",
    "    disk_radius=11,\n",
    "    do_augmentation=False,\n",
    "    module=\"multiclass_detection\",\n",
    "    include_background_channel=has_background_channel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = [0.3, 0.5, 0.7]\n",
    "thresholds = [0.3]\n",
    "best_thresh_lymph = thresholds[0]\n",
    "best_thresh_mono = thresholds[0]\n",
    "best_F1_lymph = 0.0\n",
    "best_F1_mono = 0.0\n",
    "\n",
    "visualization = False\n",
    "\n",
    "for thresh in thresholds:\n",
    "    print(f\"threshold {thresh}\")\n",
    "    counter = 0\n",
    "    sum_F1_lymph = []\n",
    "    sum_precision_lymph = []\n",
    "    sum_recall_lymph = []\n",
    "    sum_F1_mono = []\n",
    "    sum_precision_mono = []\n",
    "    sum_recall_mono = []\n",
    "    for data in tqdm(val_loader):\n",
    "        file_ids = data[\"id\"]\n",
    "        images = data[\"image\"].cuda().float()\n",
    "        gt_masks = data[\"mask\"].cuda().float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(images)\n",
    "        \n",
    "            if has_background_channel:\n",
    "                out = torch.softmax(out, dim=1)\n",
    "                lymphocyte_prob = out[:, 1, :, :]\n",
    "                monocyte_prob = out[:, 2, :, :]\n",
    "                out_pred = torch.argmax(out, dim=1)\n",
    "                mask_pred_binary = torch.zeros_like(\n",
    "                    out\n",
    "                ).scatter_(1, out_pred.unsqueeze(1), 1.)\n",
    "                lymphocyte_pred = mask_pred_binary[:,1,:,:]\n",
    "                monocyte_pred = mask_pred_binary[:,2,:,:]\n",
    "            else:\n",
    "                out = torch.sigmoid(out)\n",
    "                lymphocyte_prob = out[:, 0, :, :]\n",
    "                monocyte_prob = out[:, 1, :, :]\n",
    "                lymphocyte_pred = (lymphocyte_prob > thresh).float()\n",
    "                monocyte_pred = (monocyte_prob >= thresh).float()\n",
    "\n",
    "        if has_background_channel:\n",
    "            lymph_metrics = get_patch_F1_score_batch(\n",
    "                lymphocyte_pred, gt_masks[:, 1, :, :], out[:, 1, :, :]\n",
    "            )\n",
    "            mono_metrics = get_patch_F1_score_batch(\n",
    "                monocyte_pred, gt_masks[:, 2, :, :], out[:, 2, :, :]\n",
    "            )\n",
    "        else:\n",
    "            lymph_metrics = get_patch_F1_score_batch(\n",
    "                lymphocyte_pred, gt_masks[:, 0, :, :], out[:, 0, :, :]\n",
    "            )\n",
    "            mono_metrics = get_patch_F1_score_batch(\n",
    "                monocyte_pred, gt_masks[:, 1, :, :], out[:, 1, :, :]\n",
    "            )\n",
    "\n",
    "        sum_F1_lymph.append(lymph_metrics[\"F1\"])\n",
    "        sum_precision_lymph.append(lymph_metrics[\"Precision\"])\n",
    "        sum_recall_lymph.append(lymph_metrics[\"Recall\"])\n",
    "\n",
    "        \n",
    "        sum_F1_mono.append(mono_metrics[\"F1\"])\n",
    "        sum_precision_mono.append(mono_metrics[\"Precision\"])\n",
    "        sum_recall_mono.append(mono_metrics[\"Recall\"])\n",
    "\n",
    "    sum_F1_lymph = [x for x in sum_F1_lymph if x is not None]\n",
    "    sum_precision_lymph = [\n",
    "        x for x in sum_precision_lymph if x is not None\n",
    "    ]\n",
    "    sum_recall_lymph = [x for x in sum_recall_lymph if x is not None]\n",
    "\n",
    "    sum_F1_mono = [x for x in sum_F1_mono if x is not None]\n",
    "    sum_precision_mono = [\n",
    "        x for x in sum_precision_mono if x is not None\n",
    "    ]\n",
    "    sum_recall_mono = [x for x in sum_recall_mono if x is not None]\n",
    "\n",
    "    print(\"Lymph F1 \", np.mean(sum_F1_lymph))\n",
    "    print(\"Lymph Precision \", np.mean(sum_precision_lymph))\n",
    "    print(\"Lymph Recall \", np.mean(sum_recall_lymph))\n",
    "\n",
    "    print(\"Mono F1 \", np.mean(sum_F1_mono))\n",
    "    print(\"Mono Precision \", np.mean(sum_precision_mono))\n",
    "    print(\"Mono Recall \", np.mean(sum_recall_mono))\n",
    "\n",
    "    if np.mean(sum_F1_lymph) > best_F1_lymph:\n",
    "        best_F1_lymph = np.mean(sum_F1_lymph)\n",
    "        best_thresh_lymph = thresh\n",
    "    if np.mean(sum_F1_mono) > best_F1_mono:\n",
    "        best_F1_mono = np.mean(sum_F1_mono)\n",
    "        best_thresh_mono = thresh\n",
    "\n",
    "print(f\"best lymph threshold: {best_thresh_lymph}\")\n",
    "print(f\"best mono threshold: {best_thresh_mono}\")\n",
    "# print(f\"best F1: {best_F1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=val_fold,\n",
    "    task=1,\n",
    "    batch_size=1,\n",
    "    disk_radius=11,\n",
    "    do_augmentation=False,\n",
    "    module=\"multiclass_detection\",\n",
    "    include_background_channel=has_background_channel\n",
    ")\n",
    "\n",
    "\n",
    "lymph_thresh = 0.3\n",
    "mono_thresh = 0.3\n",
    "counter = 0\n",
    "for data in val_loader:\n",
    "    file_ids = data[\"id\"]\n",
    "    images = data[\"image\"].cuda().float()\n",
    "    gt_masks = data[\"mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(images)\n",
    "        if has_background_channel:\n",
    "            out = torch.softmax(out, dim=1)\n",
    "            lymphocyte_prob = out[:, 1, :, :]\n",
    "            monocyte_prob = out[:, 2, :, :]\n",
    "            out_pred = torch.argmax(out, dim=1)\n",
    "            mask_pred_binary = torch.zeros_like(\n",
    "                out\n",
    "            ).scatter_(1, out_pred.unsqueeze(1), 1.)\n",
    "            lymphocyte_pred = mask_pred_binary[:,1,:,:]\n",
    "            monocyte_pred = mask_pred_binary[:,2,:,:]\n",
    "        else:\n",
    "            out = torch.sigmoid(out)\n",
    "            lymphocyte_prob = out[:, 0, :, :]\n",
    "            monocyte_prob = out[:, 1, :, :]\n",
    "            lymphocyte_pred = (lymphocyte_prob > thresh).float()\n",
    "            monocyte_pred = (monocyte_prob >= thresh).float()\n",
    "\n",
    "    lymphocyte_pred = lymphocyte_pred.numpy(force=True)[0]\n",
    "    monocyte_pred = monocyte_pred.numpy(force=True)[0]\n",
    "\n",
    "    image_np = images.numpy(force=True)[0]\n",
    "    gt_mask_np = gt_masks.numpy(force=True)[0]\n",
    "    if has_background_channel:\n",
    "        gt_lymph = gt_mask_np[1]\n",
    "        gt_mono = gt_mask_np[2]\n",
    "    else:\n",
    "        gt_lymph = gt_mask_np[0]\n",
    "        gt_mono = gt_mask_np[1]\n",
    "    image_np = np.moveaxis(image_np, 0, 2)\n",
    "    image_np = imagenet_denormalise(image_np)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(10, 10))\n",
    "    axs[0].imshow(image_np)\n",
    "    axs[0].title.set_text(\"Image\")\n",
    "\n",
    "    axs[1].imshow(gt_lymph, cmap=\"gray\")\n",
    "    axs[1].title.set_text(\"Ground Truth Lymph\")\n",
    "\n",
    "    axs[2].imshow(gt_mono, cmap=\"gray\")\n",
    "    axs[2].title.set_text(\"Ground Truth Mono\")\n",
    "\n",
    "    axs[3].imshow(lymphocyte_pred, cmap=\"gray\")\n",
    "    axs[3].title.set_text(\"Pred Lymph\")\n",
    "\n",
    "    axs[4].imshow(monocyte_pred, cmap=\"gray\")\n",
    "    axs[4].title.set_text(\"Pred Mono\")\n",
    "\n",
    "    for ax in fig.axes:\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    counter += 1\n",
    "    if counter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
