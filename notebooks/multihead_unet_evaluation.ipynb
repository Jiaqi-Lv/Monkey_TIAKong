{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to evaluate multihead efficientunetb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from monkey.config import TrainingIOConfig\n",
    "from monkey.data.dataset import get_detection_dataloaders\n",
    "from monkey.model.efficientunetb0.architecture import (\n",
    "    get_multihead_efficientunet,\n",
    ")\n",
    "from monkey.model.loss_functions import get_loss_function\n",
    "from monkey.model.utils import get_activation_function\n",
    "from tqdm.autonotebook import tqdm\n",
    "from monkey.model.utils import (\n",
    "    get_multiclass_patch_F1_score_batch,\n",
    "    get_patch_F1_score_batch,\n",
    ")\n",
    "from monkey.model.loss_functions import dice_coeff\n",
    "from monkey.data.data_utils import imagenet_denormalise\n",
    "\n",
    "run_config = {\n",
    "    \"project_name\": \"Monkey_Multiclass_Detection\",\n",
    "    \"model_name\": \"multihead_unet\",\n",
    "    \"out_channels\": [2, 1, 1],\n",
    "    \"val_fold\": 1,  # [1-5]\n",
    "    \"batch_size\": 16,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"learning_rate\": 0.0004,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"epochs\": 50,\n",
    "    \"loss_function\": {\n",
    "        \"head_1\": \"BCE_Dice\",\n",
    "        \"head_2\": \"BCE_Dice\",\n",
    "        \"head_3\": \"BCE_Dice\",\n",
    "    },\n",
    "    \"do_augmentation\": False,\n",
    "    \"activation_function\": {\n",
    "        \"head_1\": \"sigmoid\",\n",
    "        \"head_2\": \"sigmoid\",\n",
    "        \"head_3\": \"sigmoid\",\n",
    "    },\n",
    "    \"use_nuclick_masks\": True,\n",
    "}\n",
    "\n",
    "IOconfig = TrainingIOConfig(\n",
    "    dataset_dir=\"/home/u1910100/Documents/Monkey/patches_256\",\n",
    ")\n",
    "\n",
    "IOconfig.set_mask_dir(\n",
    "    \"/home/u1910100/Documents/Monkey/patches_256/annotations/nuclick_masks_processed\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = get_multihead_efficientunet(\n",
    "    out_channels=run_config[\"out_channels\"], pretrained=False\n",
    ")\n",
    "checkpoint_path = f\"/home/u1910100/Documents/Monkey/runs/cell_multiclass_det/multihead_unet_experiment/fold_{run_config['val_fold']}/epoch_50.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "\n",
    "\n",
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=run_config[\"val_fold\"],\n",
    "    dataset_name=\"multitask\",\n",
    "    batch_size=run_config[\"batch_size\"],\n",
    "    do_augmentation=run_config[\"do_augmentation\"],\n",
    "    use_nuclick_masks=run_config[\"use_nuclick_masks\"],\n",
    ")\n",
    "\n",
    "\n",
    "activation_dict = {\n",
    "    \"head_1\": get_activation_function(\n",
    "        run_config[\"activation_function\"][\"head_1\"]\n",
    "    ),\n",
    "    \"head_2\": get_activation_function(\n",
    "        run_config[\"activation_function\"][\"head_2\"]\n",
    "    ),\n",
    "    \"head_3\": get_activation_function(\n",
    "        run_config[\"activation_function\"][\"head_3\"]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_unet_post_process(\n",
    "    logits_pred: torch.Tensor,\n",
    "    activation_dict: dict[str, torch.nn.Module],\n",
    "    thresholds: list = [0.3, 0.3, 0.3, 0.5],\n",
    ") -> dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Thresholds: [overall, lymph, mono, contour]\n",
    "    \"\"\"\n",
    "    head_1_logits = logits_pred[\"head_1\"]\n",
    "    head_2_logits = logits_pred[\"head_2\"]\n",
    "    head_3_logits = logits_pred[\"head_3\"]\n",
    "    pred_probs_1 = activation_dict[\"head_1\"](head_1_logits)\n",
    "    pred_probs_2 = activation_dict[\"head_2\"](head_2_logits)\n",
    "    pred_probs_3 = activation_dict[\"head_3\"](head_3_logits)\n",
    "\n",
    "    contour_pred_binary = (\n",
    "        (pred_probs_1[:, 1:2, :, :] > thresholds[3])\n",
    "        .float()\n",
    "        .numpy(force=True)\n",
    "    )\n",
    "\n",
    "    overall_pred_binary = (\n",
    "        (pred_probs_1[:, 0:1, :, :] > thresholds[0])\n",
    "        .float()\n",
    "        .numpy(force=True)\n",
    "    )\n",
    "    lymph_pred_binary = (\n",
    "        (pred_probs_2 > thresholds[1]).float().numpy(force=True)\n",
    "    )\n",
    "    mono_pred_binary = (\n",
    "        (pred_probs_3 > thresholds[2]).float().numpy(force=True)\n",
    "    )\n",
    "\n",
    "    overall_pred_binary[contour_pred_binary == 1] = 0\n",
    "    lymph_pred_binary[contour_pred_binary == 1] = 0\n",
    "    mono_pred_binary[contour_pred_binary == 1] = 0\n",
    "\n",
    "    processed_masks = {\n",
    "        \"inflamm_mask\": overall_pred_binary[:, 0, :, :],\n",
    "        \"contour_mask\": contour_pred_binary[:, 0, :, :],\n",
    "        \"lymph_mask\": lymph_pred_binary[:, 0, :, :],\n",
    "        \"mono_mask\": mono_pred_binary[:, 0, :, :],\n",
    "        \"inflamm_prob\": pred_probs_1[:, 0, :, :].numpy(force=True),\n",
    "        \"contour_prob\": pred_probs_1[:, 1, :, :].numpy(force=True),\n",
    "        \"lymph_prob\": pred_probs_2[:, 0, :, :].numpy(force=True),\n",
    "        \"mono_prob\": pred_probs_3[:, 0, :, :].numpy(force=True),\n",
    "    }\n",
    "    return processed_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_overall_score = 0.0\n",
    "running_lymph_score = 0.0\n",
    "running_mono_score = 0.0\n",
    "running_contour_score = 0.0\n",
    "\n",
    "for i, data in enumerate(\n",
    "    tqdm(val_loader, desc=\"validation\", leave=False)\n",
    "):\n",
    "    images = data[\"image\"].cuda().float()\n",
    "    inflamm_true_masks = data[\"binary_mask\"][:, 0, :, :].numpy(\n",
    "        force=True\n",
    "    )\n",
    "    contour_true_masks = (\n",
    "        data[\"contour_mask\"][:, 0, :, :].cpu().float()\n",
    "    )\n",
    "    lymph_true_masks = data[\"class_mask\"][:, 0, :, :].numpy(\n",
    "        force=True\n",
    "    )\n",
    "    mono_true_masks = data[\"class_mask\"][:, 1, :, :].numpy(force=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_pred = model(images)\n",
    "        processed_output = multihead_unet_post_process(\n",
    "            logits_pred,\n",
    "            activation_dict,\n",
    "            thresholds=[0.3, 0.3, 0.3, 0.5],\n",
    "        )\n",
    "\n",
    "    # Compute detection F1 score\n",
    "    overall_metrics = get_patch_F1_score_batch(\n",
    "        processed_output[\"inflamm_mask\"],\n",
    "        inflamm_true_masks,\n",
    "        processed_output[\"inflamm_prob\"],\n",
    "    )\n",
    "    lymph_metrics = get_patch_F1_score_batch(\n",
    "        processed_output[\"lymph_mask\"],\n",
    "        lymph_true_masks,\n",
    "        processed_output[\"lymph_prob\"],\n",
    "    )\n",
    "    mono_metrics = get_patch_F1_score_batch(\n",
    "        processed_output[\"mono_mask\"],\n",
    "        mono_true_masks,\n",
    "        processed_output[\"mono_prob\"],\n",
    "    )\n",
    "    contour_dice = dice_coeff(\n",
    "        torch.from_numpy(processed_output[\"contour_mask\"]),\n",
    "        contour_true_masks,\n",
    "        reduce_batch_first=True,\n",
    "    )\n",
    "\n",
    "    running_overall_score += (overall_metrics[\"F1\"]) * images.size(0)\n",
    "    running_lymph_score += (lymph_metrics[\"F1\"]) * images.size(0)\n",
    "    running_mono_score += (mono_metrics[\"F1\"]) * images.size(0)\n",
    "    running_contour_score += contour_dice.item() * images.size(0)\n",
    "\n",
    "results = {\n",
    "    \"overall_F1\": running_overall_score / len(val_loader.sampler),\n",
    "    \"lymph_F1\": running_lymph_score / len(val_loader.sampler),\n",
    "    \"mono_F1\": running_mono_score / len(val_loader.sampler),\n",
    "    \"contour_dice\": running_contour_score / len(val_loader.sampler),\n",
    "}\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_detection_dataloaders(\n",
    "    IOconfig,\n",
    "    val_fold=run_config[\"val_fold\"],\n",
    "    dataset_name=\"multitask\",\n",
    "    batch_size=1,\n",
    "    do_augmentation=run_config[\"do_augmentation\"],\n",
    "    use_nuclick_masks=run_config[\"use_nuclick_masks\"],\n",
    ")\n",
    "\n",
    "for i, data in enumerate(\n",
    "    tqdm(val_loader, desc=\"validation\", leave=False)\n",
    "):\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "    images = data[\"image\"].cuda().float()\n",
    "    inflamm_true_masks = data[\"binary_mask\"][:, 0, :, :].numpy(\n",
    "        force=True\n",
    "    )\n",
    "    contour_true_masks = (\n",
    "        data[\"contour_mask\"][:, 0, :, :].cpu().float()\n",
    "    )\n",
    "    lymph_true_masks = data[\"class_mask\"][:, 0, :, :].numpy(\n",
    "        force=True\n",
    "    )\n",
    "    mono_true_masks = data[\"class_mask\"][:, 1, :, :].numpy(force=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_pred = model(images)\n",
    "        processed_output = multihead_unet_post_process(\n",
    "            logits_pred,\n",
    "            activation_dict,\n",
    "            thresholds=[0.3, 0.3, 0.3, 0.5],\n",
    "        )\n",
    "\n",
    "    images = images.numpy(force=True)[0]\n",
    "    images = np.moveaxis(images, 0, 2)\n",
    "    images = imagenet_denormalise(images)\n",
    "\n",
    "    axes[0][0].imshow(images)\n",
    "    axes[0][0].set_title(\"Image\")\n",
    "\n",
    "    axes[0][1].imshow(inflamm_true_masks[0], cmap=\"gray\")\n",
    "    axes[0][1].set_title(\"True Overall\")\n",
    "\n",
    "    axes[0][2].imshow(contour_true_masks[0], cmap=\"gray\")\n",
    "    axes[0][2].set_title(\"True Contour\")\n",
    "\n",
    "    axes[1][0].imshow(lymph_true_masks[0], cmap=\"gray\")\n",
    "    axes[1][0].set_title(\"True Lymph\")\n",
    "\n",
    "    axes[1][1].imshow(mono_true_masks[0], cmap=\"gray\")\n",
    "    axes[1][1].set_title(\"True Mono\")\n",
    "\n",
    "    axes[1][2].imshow(\n",
    "        processed_output[\"contour_mask\"][0], cmap=\"gray\"\n",
    "    )\n",
    "    axes[1][2].set_title(\"Pred Contour\")\n",
    "\n",
    "    axes[2][0].imshow(processed_output[\"lymph_mask\"][0], cmap=\"gray\")\n",
    "    axes[2][0].set_title(\"Pred Lymph\")\n",
    "\n",
    "    axes[2][1].imshow(processed_output[\"mono_mask\"][0], cmap=\"gray\")\n",
    "    axes[2][1].set_title(\"Pred Mono\")\n",
    "\n",
    "    axes[2][2].imshow(\n",
    "        processed_output[\"inflamm_mask\"][0], cmap=\"gray\"\n",
    "    )\n",
    "    axes[2][2].set_title(\"Pred Overall\")\n",
    "\n",
    "    for ax in axes.ravel():\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    if i > 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
